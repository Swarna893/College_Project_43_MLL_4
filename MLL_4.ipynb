{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43126ee3-388b-4f0c-97ad-e5d2f4cd2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"MLL_4.xlsx\"   # Make sure the file is in the same folder as your notebook\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1067a3-f469-4951-8839-cfa606384230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31307  31308_at  31309_r_at  31310_at  31311_at  31312_at  31313_at  \\\n",
      "0 -135.7    -100.1       -94.6      -230       0.6     -50.4     -36.3   \n",
      "1  -80.0     -23.0        -6.0      -145     491.0     290.0    -235.0   \n",
      "2  -91.0    -130.0       -27.0       -51     236.0    -163.0    -304.0   \n",
      "3 -144.0    -124.0       -26.0      -139     -88.0      34.0    -411.0   \n",
      "4  -89.0     -25.0       -64.0      -112     452.0     183.0     107.0   \n",
      "\n",
      "   31314_at  31315_at  31316_at  ...  101_at  102_at  103_at  104_at  105_at  \\\n",
      "0     139.5      31.6     -32.2  ...  -225.2   242.5   101.7   473.1   -59.9   \n",
      "1      41.0    4602.0     -37.0  ...  -175.0   143.0    96.0   301.0   -50.0   \n",
      "2     -35.0     498.0     -56.0  ...  -308.0   184.0   -32.0   350.0   -11.0   \n",
      "3     118.0    -239.0    -104.0  ...   731.0   106.0  -330.0   -36.0  -190.0   \n",
      "4     233.0      38.0     -35.0  ...   182.0   426.0   155.0   607.0    50.0   \n",
      "\n",
      "   106_at  107_at  108_g_at  109_at  class  \n",
      "0   217.9   275.6    -461.6  1115.5      0  \n",
      "1   242.0   222.0    -330.0  2481.0      0  \n",
      "2   837.0   174.0     -99.0   376.0      0  \n",
      "3   999.0   255.0    -353.0  1603.0      0  \n",
      "4   249.0  1635.0    -780.0  1103.0      0  \n",
      "\n",
      "[5 rows x 12534 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bb0d13-62b1-4553-9772-b33d9856d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72 entries, 0 to 71\n",
      "Columns: 12534 entries, 31307 to class\n",
      "dtypes: float64(11224), int64(1310)\n",
      "memory usage: 6.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check basic info\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e02500-8324-46f3-a181-2e44a5dc45fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            31307    31308_at  31309_r_at    31310_at     31311_at  \\\n",
      "count   72.000000   72.000000   72.000000   72.000000    72.000000   \n",
      "mean  -188.495833  -94.098611  -31.716667  -37.708333   376.938889   \n",
      "std     97.886654  149.780756   45.519842  167.468596   274.066937   \n",
      "min   -398.000000 -875.000000 -149.000000 -545.000000  -173.000000   \n",
      "25%   -251.000000 -152.000000  -64.000000 -130.500000   178.500000   \n",
      "50%   -167.000000  -65.000000  -30.000000  -74.500000   340.500000   \n",
      "75%   -115.750000  -19.500000   -8.250000   79.000000   537.750000   \n",
      "max     75.000000  132.000000   92.000000  377.000000  1059.000000   \n",
      "\n",
      "         31312_at     31313_at    31314_at     31315_at    31316_at  ...  \\\n",
      "count   72.000000    72.000000   72.000000    72.000000   72.000000  ...   \n",
      "mean    -7.130556  -397.726389   27.729167   538.091667  -67.266667  ...   \n",
      "std    190.598033   323.552802  196.632494  1230.456868   53.191909  ...   \n",
      "min   -710.000000 -1446.000000 -640.000000  -572.000000 -320.000000  ...   \n",
      "25%    -75.500000  -584.000000  -78.750000  -106.250000  -94.500000  ...   \n",
      "50%     34.000000  -367.000000   51.500000    34.800000  -64.500000  ...   \n",
      "75%    127.250000  -167.000000  164.750000   655.500000  -32.800000  ...   \n",
      "max    290.000000   151.000000  502.000000  5787.000000   38.000000  ...   \n",
      "\n",
      "            101_at      102_at       103_at       104_at      105_at  \\\n",
      "count    72.000000   72.000000    72.000000    72.000000   72.000000   \n",
      "mean    -57.780556  183.590278   126.329167   500.098611    4.515278   \n",
      "std     388.090112  132.052602   231.256722   240.975392  120.956464   \n",
      "min    -935.000000  -37.000000  -330.000000   -36.000000 -313.000000   \n",
      "25%    -340.500000   93.000000    21.250000   350.750000  -64.500000   \n",
      "50%    -118.500000  142.500000    86.000000   454.000000    4.500000   \n",
      "75%     176.000000  241.375000   215.500000   628.000000   79.250000   \n",
      "max    1010.000000  528.000000  1212.000000  1101.000000  251.000000   \n",
      "\n",
      "            106_at       107_at     108_g_at       109_at      class  \n",
      "count    72.000000    72.000000    72.000000    72.000000  72.000000  \n",
      "mean   1057.665278   366.438889  -993.938889  1119.937500   1.055556  \n",
      "std    1311.734783   538.404428   692.766342   608.321056   0.853970  \n",
      "min      -6.000000  -598.000000 -3352.000000  -395.000000   0.000000  \n",
      "25%     284.750000     9.750000 -1354.250000   735.000000   0.000000  \n",
      "50%     548.000000   243.500000  -904.000000  1028.500000   1.000000  \n",
      "75%    1356.000000   663.000000  -457.700000  1543.500000   2.000000  \n",
      "max    7567.000000  2512.000000   -18.000000  2926.000000   2.000000  \n",
      "\n",
      "[8 rows x 12534 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check summary statistics for numeric columns\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94651fd1-c7c5-4ed2-ad65-9ceefb81b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31307         0\n",
      "31308_at      0\n",
      "31309_r_at    0\n",
      "31310_at      0\n",
      "31311_at      0\n",
      "             ..\n",
      "106_at        0\n",
      "107_at        0\n",
      "108_g_at      0\n",
      "109_at        0\n",
      "class         0\n",
      "Length: 12534, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many missing values each column has\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51b2e37-6250-4c48-8c3f-772ddef5cba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([       31307,   '31308_at', '31309_r_at',   '31310_at',   '31311_at',\n",
      "         '31312_at',   '31313_at',   '31314_at',   '31315_at',   '31316_at',\n",
      "       ...\n",
      "           '101_at',     '102_at',     '103_at',     '104_at',     '105_at',\n",
      "           '106_at',     '107_at',   '108_g_at',     '109_at',      'class'],\n",
      "      dtype='object', length=12534)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a272dd9-ef12-4257-a3c4-9ecf81eb4086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "2    28\n",
      "0    24\n",
      "1    20\n",
      "Name: count, dtype: int64\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Check distinct class labels and their counts\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# Check the unique values directly\n",
    "print(df['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb05bac4-701d-415d-9305-6644d8dc5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae26ef56-843f-44c6-af53-fb7c45458071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.9722222222222222\n",
      "\n",
      "ðŸ“Š Confusion Matrix:\n",
      " [[11  0  1]\n",
      " [ 0 10  0]\n",
      " [ 0  0 14]]\n",
      "\n",
      "ðŸ“ˆ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "Saved: rf_model.pkl and scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# 1) Ensure column names are strings (important for scikit-learn)\n",
    "df.columns = df.columns.astype(str)\n",
    "\n",
    "# 2) Shuffle / randomize the dataset (keeps target distribution when we stratify later)\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 3) Separate features and target\n",
    "target_col = 'class'   # as confirmed earlier\n",
    "X = df_shuffled.drop(columns=[target_col])\n",
    "y = df_shuffled[target_col]\n",
    "\n",
    "# 4) Normalize features\n",
    "#    Using StandardScaler (zero mean, unit variance). If you prefer MinMax use MinMaxScaler instead.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # returns numpy array\n",
    "\n",
    "# If you want X as a DataFrame with same column names (optional)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# 5) Train/test split (stratify to preserve class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled_df, y, test_size=0.5, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 6) Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 7) Predict & Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(\"âœ… Accuracy:\", accuracy)\n",
    "print(\"\\nðŸ“Š Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nðŸ“ˆ Classification Report:\\n\", report)\n",
    "\n",
    "# 8) Save model and scaler for later use\n",
    "joblib.dump(rf_model, \"rf_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\nSaved: rf_model.pkl and scaler.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
